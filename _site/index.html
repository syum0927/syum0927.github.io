<!doctype html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
       &middot; Avatron
    
  </title>

  <link rel="stylesheet" href="/styles.css">
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/assets/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/assets/favicon.ico">
  <link rel="alternate" type="application/atom+xml" title="Avatron" href="/atom.xml">

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Avatron" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Avatron" />
<script type="application/ld+json">
{"@type":"WebSite","name":"Avatron","headline":"Avatron","url":"http://localhost:4000/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">Avatron</a>
          <small></small>
        </h3>
      </header>

      <main>
        <h1 id="avatron--3d-face-avatar-and-voice-generation-from-text">Avatron : 3D Face Avatar and Voice Generation from Text</h1>

<h3 id="anonymous-cvpr-submission--paper-id-8800">Anonymous CVPR submission : Paper ID 8800</h3>

<hr />

<video controls="" style="width: 1200px"><source src="./assets/demo_intro.mp4" type="video/mp4" /></video>

<h2 id="abstract">Abstract</h2>

<p>We propose a novel 3D facial animation model that does not require explicit temporal synchronization between talking faces and speech. Our model presents a solution to a chronic problem that exists in current speech-driven 3D facial animation. Due to time domain differences between videos and speech, most approaches apply downsampling or upsampling to linguistic features from a pre-trained automatic speech recognition (ASR) model, resulting in unnatural facial movements. However, we efficiently utilize intermediate features from a text-to-speech (TTS) model to solve this problem. We upsample the text embedding of a non-autoregressive TTS model to the length of a mel-spectrogram and feed it into an avatar model to be converted to the vertices of a 3D face avatar. Since our proposed model does not require an ASR model, we are able to reduce the number of parameters and computational complexity of the whole solution. GAN-based training is also used to obtain vivid human-like facial movements. Our model demonstrates good effectiveness and performance in terms of normalized vertices mean error, as well as two subjective evaluations, SMOS and MOS.</p>

<hr />

<hr />

<h2 id="normalized-vertices-mean-error-nvme">Normalized Vertices Mean Error (NVME)</h2>

<p>We compute vertices error between the reference and predicted 3D face mesh. The difference between the 3D mesh from the reference is represented by its color. The bluer the color of the 3D mesh, the smaller the difference, and the red the mesh, the larger the difference. Avatron shows a smaller overall error than FaceFormer. We colorize 3D mesh using an average error of three vertices which consist of each face.</p>

<h3 id="avatron-vs-faceformer">Avatron vs. Faceformer</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><video controls="" style="width: 1200px"><source src="./assets/nvme/01.mp4" type="video/mp4" /></video></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 1200px"><source src="./assets/nvme/02.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 1200px"><source src="./assets/nvme/03.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 1200px"><source src="./assets/nvme/04.mp4" type="video/mp4" /></video></td>
    </tr>
  </tbody>
</table>

<pre>
  

</pre>

<h2 id="similarity-mean-opinion-score-smos">Similarity Mean Opinion Score (SMOS)</h2>

<p>We provide three samples of FaceFormer and Avatron with reference. All samples from FaceFormer move around the mouth only, so they can convey linguistic information, but they do not describe a facial expression. In contrast, Avatron’s samples provide not only context but also facial movements, making avatars more natural.</p>

<h3 id="avatron-vs-faceformer-1">Avatron vs Faceformer</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Reference</th>
      <th style="text-align: center">Faceformer</th>
      <th style="text-align: center">Avatron</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/reference/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/faceformer/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/avatron/01.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/reference/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/faceformer/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/avatron/02.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/reference/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/faceformer/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/avatron/03.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/reference/04.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/faceformer/04.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/avatron/04.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/reference/05.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/faceformer/05.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_face/avatron/05.mp4" type="video/mp4" /></video></td>
    </tr>
  </tbody>
</table>

<pre>



</pre>

<h2 id="mean-opinion-score-mos">Mean Opinion Score (MOS)</h2>

<p>We provide two samples of FaceFormer and Avatron with reference. Unlike SMOS samples, MOS samples are generated from duration predictor of TTS. Because of one-to-many mapping problem, reference and others have different durations. Avatron’s performance does not lag behind even though it contains only 48.5% of the parameters compared to FaceFormer.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Reference</th>
      <th style="text-align: center">Faceformer</th>
      <th style="text-align: center">Avatron</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ref_select/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ff_select/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ava_select/01.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ref_select/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ff_select/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ava_select/02.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ref_select/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ff_select/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ava_select/03.mp4" type="video/mp4" /></video></td>
    </tr>
  </tbody>
</table>

<pre>
  

</pre>

<h2 id="ablation-study-advantage-of-tts">Ablation study: Advantage of TTS</h2>

<p>We generate speech samples with modified speaking speeds and their corresponding 3D facial animations. We are able to control the tempo of the sample (slowing or speeding up) by controlling the estimated phoneme duration from the predictor in Avatron. FaceFormer cannot control the avatar tempo because it used the fixed-length speech as input.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Normal</th>
      <th style="text-align: center">Fast</th>
      <th style="text-align: center">Slow</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/normal/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/fast/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/slow/01.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/normal/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/fast/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/slow/02.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/normal/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/fast/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/slow/03.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/normal/04.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/fast/04.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ablation_speed/slow/04.mp4" type="video/mp4" /></video></td>
    </tr>
  </tbody>
</table>

<pre>
  

</pre>

<h2 id="ablation-study-effect-of-gan-based-training-crietrion">Ablation study: Effect of GAN-based training crietrion</h2>

<p>The GAN-based training method helps the model generate facial movements that are more similar to the reference in terms of facial expressions.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Reference</th>
      <th style="text-align: center">Avatron w/o GAN</th>
      <th style="text-align: center">Avatron</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_nogan/reference/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_nogan/avatron_nogan/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_nogan/avatron/01.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_nogan/reference/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_nogan/avatron_nogan/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/ava_nogan/avatron/02.mp4" type="video/mp4" /></video></td>
    </tr>
  </tbody>
</table>

<pre>

</pre>

<h2 id="mean-opinion-score-mos-1">Mean Opinion Score (MOS)</h2>

<p>We provide two samples of FaceFormer and Avatron with reference. Unlike SMOS samples, MOS samples are generated from duration predictor of TTS. Because of one-to-many mapping problem, reference and others have different durations. Avatron’s performance does not lag behind even though it contains only 48.5% of the parameters compared to FaceFormer.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Reference</th>
      <th style="text-align: center">Faceformer</th>
      <th style="text-align: center">Avatron</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ref_select/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ff_select/01.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ava_select/01.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ref_select/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ff_select/02.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ava_select/02.mp4" type="video/mp4" /></video></td>
    </tr>
    <tr>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ref_select/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ff_select/03.mp4" type="video/mp4" /></video></td>
      <td style="text-align: center"><video controls="" style="width: 400px"><source src="./assets/mos/ava_select/03.mp4" type="video/mp4" /></video></td>
    </tr>
  </tbody>
</table>


      </main>

      <footer class="footer">
        <small>
          &copy; <time datetime="2022-11-21T21:19:01+09:00">2022</time>. All rights reserved.
        </small>
      </footer>
    </div>

    
  </body>
</html>
